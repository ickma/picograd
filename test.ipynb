{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits, load_iris\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "print(digits.data.shape)\n",
    "print(digits.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    digits.data/np.max(digits.data), digits.target, test_size=0.1, random_state=42)\n",
    "# X_train = X_train[:200]\n",
    "# X_test = X_test[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.layer import Layer\n",
    "\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.layer1 = Layer(in_dim, 5)\n",
    "        self.layer2 = Layer(5, 5)\n",
    "        self.layer3 = Layer(5, out_dim)\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1.forward(x)\n",
    "        out = [x.relu() for x in out]\n",
    "        out = self.layer2.forward(out)\n",
    "        out = [x.relu() for x in out]\n",
    "        out = self.layer3.forward(out)\n",
    "        # out = [x.relu() for x in out]\n",
    "        # Apply softmax activation to the output layer\n",
    "        exp_out = [x.exp() for x in out]\n",
    "        sum_exp = sum(exp_out)\n",
    "        out = [x / sum_exp for x in exp_out]\n",
    "        return out\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for layer in [self.layer1, self.layer2,self.layer3]:\n",
    "            for p in layer.weights:\n",
    "                p.grad = 0\n",
    "            for p in layer.biases:\n",
    "                p.grad = 0\n",
    "                \n",
    "    def learn(self, learning_rate):\n",
    " \n",
    "        for layer in [self.layer1, self.layer2,self.layer3]:\n",
    "            for p in layer.weights:\n",
    "                p.value = p.value - (learning_rate * p.grad)\n",
    "          \n",
    "            for p in layer.biases:\n",
    "                p.value = p.value - (learning_rate * p.grad)\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "learning_rate: 0.9\n",
      "[Parameter(0.04779756632501065), Parameter(0.04775704759523418), Parameter(0.033561061585948314), Parameter(0.15707329860057356), Parameter(0.021471236216949057), Parameter(0.21586836628821587), Parameter(0.0333147514613562), Parameter(0.09107855944199482), Parameter(0.21568289112357136), Parameter(0.13639522136114604)]\n",
      "9\n",
      "Accuracy: 0.08\n",
      "Epoch 2/100\n",
      "learning_rate: 0.8181818181818181\n"
     ]
    }
   ],
   "source": [
    "model = Model(len(X_train[0]), len(np.unique(y_train)))\n",
    "\n",
    "batch_size = len(X_train)//10\n",
    "epochs = 100\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    learning_rate = .9 / (1 + 0.1 * epoch)  # Stochastic Gradient Descent (SGD) with learning rate decay\n",
    "    # learning_rate = 0.3\n",
    "    print(f\"learning_rate: {learning_rate}\")\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        model.zero_grad()\n",
    "        error_list = []\n",
    "        for j in range(batch_size):\n",
    "            if i+j >= len(X_train):\n",
    "                break\n",
    "            x = (X_train[i+j]/1.0).tolist()\n",
    "            y = int(y_train[i+j])\n",
    "            out = model.forward(x)\n",
    "            # errors = [\n",
    "            #     (out[i]-1 if i == y else out[i])**2 for i in range(len(out))\n",
    "            # ]\n",
    "            # Calculate cross-entropy error\n",
    "            target = [1 if i == y else 0 for i in range(len(out))]\n",
    "            errors = [-target[i] * out[i].sigmoid().log() - (1 - target[i]) * (1 - out[i].sigmoid()).log() for i in range(len(out))]\n",
    "            error_list.extend(errors)\n",
    "        loss = sum(error_list)/len(error_list)\n",
    "        loss.grad=1\n",
    "        loss.backward()\n",
    "        model.learn(learning_rate)\n",
    "        # print(f\"loss: {loss.value}\")\n",
    "\n",
    "    # evaluate\n",
    "    correct = 0\n",
    "    import numpy as np\n",
    "    for i in range(len(X_test)):\n",
    "        x = (X_test[i]/1.0).tolist()\n",
    "        y = int(y_test[i])\n",
    "        out = model.forward(x)\n",
    "        if np.argmax([o.value for o in out]) == y:\n",
    "            correct += 1\n",
    "    print(model.forward(X_test[1]))\n",
    "    print(y_test[1])\n",
    "    print(f\"Accuracy: {correct/len(X_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter(0.18654696309633526), Parameter(0.490600594419033), Parameter(-0.15887579534056473), Parameter(1.030787811385254), Parameter(0.3758973046304542), Parameter(-0.9183937614446892), Parameter(1.4036926874536162), Parameter(0.025502060608008657), Parameter(-0.0363322899519338), Parameter(-0.8481017723224151), Parameter(1.5644075803317388), Parameter(-0.02881003209777139), Parameter(-0.049863216923649346), Parameter(-0.8329875244359635), Parameter(0.5847990256351847), Parameter(-0.1949970347061038), Parameter(-0.8758314715840874), Parameter(-0.126100230675104), Parameter(-0.7121091837119458), Parameter(0.568469323334188)]\n",
      "[Parameter(-0.09250598978534469), Parameter(-0.033834234976438435), Parameter(0.07622701902181019), Parameter(0.4583369051629912), Parameter(-0.4007289176745161)]\n",
      "[Parameter(0.7686391472435841), Parameter(0.7677088138626311), Parameter(-0.9925691212387548), Parameter(0.6969022404989409), Parameter(-0.7827066468369663), Parameter(0.12472312727543793), Parameter(0.7747972395145886), Parameter(0.10366743938461251), Parameter(0.973848524785216), Parameter(-0.588559161762471), Parameter(0.3561412258567605), Parameter(1.0440535806382076), Parameter(1.187107476058042), Parameter(0.5851620677894208), Parameter(0.3969280946331373), Parameter(-0.49021847994999246), Parameter(-0.8921136419701972), Parameter(0.9996054366894673), Parameter(-0.12324100053094234), Parameter(-0.6246169271484587), Parameter(-0.4508219179183833), Parameter(1.1840280911756935), Parameter(0.9586054743510916), Parameter(0.8419326983930399), Parameter(0.6503461437179812)]\n",
      "[Parameter(-0.6899816415795881), Parameter(1.2007471855111165), Parameter(-0.34739403924078316), Parameter(-0.053656287555896576), Parameter(-0.09398408900605469)]\n",
      "[Parameter(-0.5626791717716779), Parameter(0.8465780247094333), Parameter(-1.2250545491634308), Parameter(0.9013814474956372), Parameter(-1.4069715595375853), Parameter(0.5828344178814946), Parameter(0.4184233832375996), Parameter(-0.5560702401362284), Parameter(-0.3311965000032988), Parameter(0.533249579701505), Parameter(0.43091523612598936), Parameter(-0.33538370572985027), Parameter(1.3132711236983061), Parameter(0.32157797656617326), Parameter(0.12008088295154479)]\n",
      "[Parameter(1.063161458446602), Parameter(-0.1984732469001874), Parameter(-0.12607138546022173)]\n"
     ]
    }
   ],
   "source": [
    "for layer in [model.layer1, model.layer2, model.layer3]:\n",
    "    print(layer.weights)\n",
    "    print(layer.biases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
